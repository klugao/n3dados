# Sistema de PrediÃ§Ã£o de EvasÃ£o Estudantil

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um sistema completo de prediÃ§Ã£o de evasÃ£o estudantil utilizando tÃ©cnicas de Machine Learning. O objetivo Ã© identificar estudantes com alto risco de evasÃ£o nos primeiros semestres, permitindo intervenÃ§Ãµes preventivas personalizadas.

**Trabalho Final - N3 - CiÃªncia de Dados**

---

## ğŸ“ Estrutura do Projeto

```
n3dados/
â”œâ”€â”€ README.md                    # Este arquivo - RelatÃ³rio completo do projeto
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ modelo_final.pkl            # Modelo treinado salvo (gerado apÃ³s execuÃ§Ã£o)
â”œâ”€â”€ data/                       # Dataset
â”‚   â””â”€â”€ student_dropout_dataset.csv
â”œâ”€â”€ notebooks/                   # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_eda_exploratoria.ipynb
â”‚   â””â”€â”€ 02_modelagem_avaliacao.ipynb
â””â”€â”€ scripts/                    # Scripts auxiliares
    â”œâ”€â”€ download_real_dataset.py # Download e preparaÃ§Ã£o de dataset real
    â”œâ”€â”€ generate_dataset.py      # GeraÃ§Ã£o de dados sintÃ©ticos
    â””â”€â”€ deploy_model.py          # Script de deploy e previsÃ£o
```

---

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passo 1: InstalaÃ§Ã£o das DependÃªncias

Primeiro, instale todas as dependÃªncias necessÃ¡rias:

```bash
pip install -r requirements.txt
```

**Nota**: Recomenda-se usar um ambiente virtual (venv) para isolar as dependÃªncias:

```bash
# Criar ambiente virtual (opcional, mas recomendado)
python -m venv venv

# Ativar ambiente virtual
# No macOS/Linux:
source venv/bin/activate
# No Windows:
# venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### Passo 2: PreparaÃ§Ã£o do Dataset

VocÃª precisa ter um dataset antes de executar os notebooks. VocÃª tem duas opÃ§Ãµes:

#### OpÃ§Ã£o A: Dataset Real (Recomendado)

```bash
python scripts/download_real_dataset.py
```

Este script:
- Tenta baixar automaticamente o dataset do UCI Machine Learning Repository
- Se nÃ£o conseguir baixar, cria um dataset de exemplo baseado em padrÃµes reais
- Salva o dataset em `data/student_dropout_dataset.csv`

#### OpÃ§Ã£o B: Dataset SintÃ©tico (Alternativa)

```bash
python scripts/generate_dataset.py
```

Este script:
- Gera um dataset sintÃ©tico de 1000 estudantes
- Ãštil para testes rÃ¡pidos ou quando nÃ£o hÃ¡ acesso Ã  internet
- Salva o dataset em `data/student_dropout_dataset.csv`

**VerificaÃ§Ã£o**: ApÃ³s executar qualquer uma das opÃ§Ãµes, verifique se o arquivo foi criado:

```bash
ls -lh data/student_dropout_dataset.csv
```

### Passo 3: ExecuÃ§Ã£o dos Notebooks

Execute os notebooks na seguinte ordem usando Jupyter:

#### 3.1 Iniciar o Jupyter Notebook

```bash
jupyter notebook
```

Isso abrirÃ¡ o Jupyter no seu navegador.

#### 3.2 Executar os Notebooks na Ordem

1. **`notebooks/01_eda_exploratoria.ipynb`**
   - AnÃ¡lise exploratÃ³ria dos dados
   - VisualizaÃ§Ãµes e estatÃ­sticas descritivas
   - Execute todas as cÃ©lulas (Menu: Cell â†’ Run All)

2. **`notebooks/02_modelagem_avaliacao.ipynb`**
   - Treinamento de trÃªs modelos (RegressÃ£o LogÃ­stica, Random Forest, KNN)
   - AvaliaÃ§Ã£o comparativa
   - SeleÃ§Ã£o do melhor modelo
   - **IMPORTANTE**: Este notebook salva automaticamente:
     - `modelo_final.pkl` (modelo treinado)
     - `scaler.pkl` (normalizador)
     - `label_encoders.pkl` (encoders de variÃ¡veis categÃ³ricas)
   - Execute todas as cÃ©lulas (Menu: Cell â†’ Run All)

**Alternativa**: Se preferir usar JupyterLab:

```bash
jupyter lab
```

### Passo 4: Deploy e Teste do Modelo

ApÃ³s executar o notebook `02_modelagem_avaliacao.ipynb`, vocÃª pode testar o modelo treinado:

```bash
python scripts/deploy_model.py
```

Este script:
- Carrega o modelo salvo (`modelo_final.pkl`)
- Demonstra prediÃ§Ãµes com dois exemplos:
  - Estudante com **alto risco** de evasÃ£o
  - Estudante com **baixo risco** de evasÃ£o
- Mostra probabilidades e recomendaÃ§Ãµes

**Troubleshooting**: Se aparecer erro de "Modelo nÃ£o encontrado", certifique-se de que:
1. Executou completamente o notebook `02_modelagem_avaliacao.ipynb`
2. Os arquivos `modelo_final.pkl`, `scaler.pkl` e `label_encoders.pkl` foram criados na raiz do projeto

### Resumo RÃ¡pido (TL;DR)

```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Gerar/baixar dataset
python scripts/generate_dataset.py
# OU
python scripts/download_real_dataset.py

# 3. Executar notebooks (no Jupyter)
jupyter notebook
# Depois execute: notebooks/01_eda_exploratoria.ipynb
# Depois execute: notebooks/02_modelagem_avaliacao.ipynb

# 4. Testar modelo
python scripts/deploy_model.py
```

---

## ğŸ“Š Parte 1: A FundaÃ§Ã£o do Projeto - O Problema de NegÃ³cio (1,0 ponto)

### 1.1 DomÃ­nio do Problema

O projeto se insere no contexto educacional, onde instituiÃ§Ãµes de ensino superior enfrentam um desafio crÃ­tico: **a evasÃ£o estudantil**. 

**Contexto e RelevÃ¢ncia:**
- A evasÃ£o estudantil representa um problema significativo que impacta nÃ£o apenas as instituiÃ§Ãµes de ensino (perda de receita, recursos investidos), mas tambÃ©m os prÃ³prios estudantes (frustraÃ§Ã£o, dÃ­vidas, oportunidades perdidas) e a sociedade como um todo (menor qualificaÃ§Ã£o profissional, impacto econÃ´mico).
- Estudos indicam que a maioria das evasÃµes ocorre nos primeiros semestres, quando intervenÃ§Ãµes preventivas podem ser mais eficazes.
- Identificar estudantes em risco precocemente permite que a instituiÃ§Ã£o ofereÃ§a suporte personalizado, melhorando as taxas de retenÃ§Ã£o e sucesso acadÃªmico.

### 1.2 Pergunta de NegÃ³cio

**"Quais caracterÃ­sticas de um estudante (acadÃªmicas, comportamentais, financeiras e demogrÃ¡ficas) tÃªm maior impacto na probabilidade de evasÃ£o nos primeiros semestres?"**

Esta pergunta guia toda a anÃ¡lise e modelagem, buscando identificar os fatores mais preditivos de evasÃ£o para que a instituiÃ§Ã£o possa focar seus esforÃ§os de intervenÃ§Ã£o.

### 1.3 Objetivo do Modelo

O objetivo Ã© construir um **modelo de classificaÃ§Ã£o binÃ¡ria** capaz de:

- Identificar estudantes com **alto risco de evasÃ£o** antes que o problema se agrave
- Fornecer uma **probabilidade de evasÃ£o** para cada estudante
- Permitir que a instituiÃ§Ã£o priorize intervenÃ§Ãµes baseadas em risco
- Apoiar decisÃµes estratÃ©gicas de retenÃ§Ã£o estudantil

O modelo serÃ¡ utilizado como ferramenta de apoio Ã  decisÃ£o, permitindo que coordenadores, tutores e equipes de apoio estudantil identifiquem proativamente estudantes que precisam de atenÃ§Ã£o especial.

---

## ğŸ”„ Parte 2: A Jornada dos Dados - Pipeline e Arquitetura (1,0 ponto)

### 2.1 Origem e RepositÃ³rio de Dados

**Fonte dos Dados:**
- **Dataset Real**: Dados baseados no dataset "Predict students' dropout and academic success" do UCI Machine Learning Repository, com caracterÃ­sticas reais de estudantes
- **Dataset SintÃ©tico** (alternativa): Dados gerados programaticamente baseados no schema do projeto N1 (integraÃ§Ã£o MongoDB + PostgreSQL)
- Ambos os datasets incluem dados acadÃªmicos, comportamentais, financeiros e demogrÃ¡ficos

**Arquitetura de Armazenamento:**
- **Data Lakehouse** (Bronze â†’ Silver â†’ Gold)
- **Justificativa da Arquitetura:**
  - **Flexibilidade**: Suporta mÃºltiplos formatos de dados (CSV, Parquet, etc.)
  - **GovernanÃ§a**: Permite rastreabilidade e versionamento dos dados
  - **PreparaÃ§Ã£o para ML**: Estrutura otimizada para pipelines de Machine Learning
  - **Escalabilidade**: Pode crescer conforme a necessidade da instituiÃ§Ã£o
  - **Custo-efetividade**: Mais econÃ´mico que soluÃ§Ãµes tradicionais de Data Warehouse

### 2.2 Pipeline de Dados

O pipeline completo segue as seguintes etapas:

#### **Diagrama Visual do Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FONTE DE DADOS                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  UCI ML Repo     â”‚         â”‚  Dataset         â”‚            â”‚
â”‚  â”‚  (Real)          â”‚         â”‚  SintÃ©tico       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                             â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                             â”‚
             â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         INGESTÃƒO (Bronze Layer)            â”‚
    â”‚  â€¢ download_real_dataset.py                â”‚
    â”‚  â€¢ generate_dataset.py                     â”‚
    â”‚  â€¢ Armazenamento: data/student_*.csv      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    LIMPEZA E TRANSFORMAÃ‡ÃƒO (ETL)          â”‚
    â”‚  â€¢ Tratamento de valores ausentes         â”‚
    â”‚  â€¢ PadronizaÃ§Ã£o de formatos               â”‚
    â”‚  â€¢ RemoÃ§Ã£o de duplicatas                    â”‚
    â”‚  â€¢ CriaÃ§Ã£o de features derivadas           â”‚
    â”‚    (success_rate, failure_rate, etc.)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ANÃLISE EXPLORATÃ“RIA (EDA) - Silver      â”‚
    â”‚  â€¢ EstatÃ­sticas descritivas                â”‚
    â”‚  â€¢ VisualizaÃ§Ãµes e correlaÃ§Ãµes              â”‚
    â”‚  â€¢ IdentificaÃ§Ã£o de padrÃµes                 â”‚
    â”‚  â€¢ Notebook: 01_eda_exploratoria.ipynb    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    PREPARAÃ‡ÃƒO PARA MODELAGEM (Gold)        â”‚
    â”‚  â€¢ SeleÃ§Ã£o de features                      â”‚
    â”‚  â€¢ Label Encoding (variÃ¡veis categÃ³ricas)   â”‚
    â”‚  â€¢ NormalizaÃ§Ã£o (StandardScaler)            â”‚
    â”‚  â€¢ DivisÃ£o Train/Test (80/20, stratified)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         MODELAGEM E AVALIAÃ‡ÃƒO              â”‚
    â”‚  â€¢ Treinamento de 3 modelos                 â”‚
    â”‚  â€¢ AvaliaÃ§Ã£o com mÃºltiplas mÃ©tricas         â”‚
    â”‚  â€¢ SeleÃ§Ã£o do melhor modelo                 â”‚
    â”‚  â€¢ Notebook: 02_modelagem_avaliacao.ipynb â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              DEPLOY                        â”‚
    â”‚  â€¢ Salvamento do modelo (joblib)           â”‚
    â”‚  â€¢ Script de deploy (deploy_model.py)      â”‚
    â”‚  â€¢ PrediÃ§Ãµes em produÃ§Ã£o                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **IngestÃ£o**
- Script `download_real_dataset.py` baixa e prepara dataset real de evasÃ£o estudantil
- Alternativamente, script `generate_dataset.py` cria dataset sintÃ©tico unificado
- Dados sÃ£o preparados/gerados com base em distribuiÃ§Ãµes e padrÃµes realistas
- Dataset contÃ©m aproximadamente 1000 registros de estudantes

#### **Limpeza e TransformaÃ§Ã£o (ETL)**
- **Tratamento de valores ausentes**: VerificaÃ§Ã£o e preenchimento quando necessÃ¡rio
- **PadronizaÃ§Ã£o de formatos**: Garantia de consistÃªncia nos tipos de dados
- **RemoÃ§Ã£o de duplicatas**: IdentificaÃ§Ã£o e remoÃ§Ã£o de registros duplicados
- **CriaÃ§Ã£o de features derivadas**: 
  - `success_rate`: Taxa de sucesso em cursos
  - `failure_rate`: Taxa de reprovaÃ§Ã£o
  - `interaction_per_enrollment`: InteraÃ§Ãµes por matrÃ­cula

#### **AnÃ¡lise ExploratÃ³ria (EDA)**
- Realizada no notebook `01_eda_exploratoria.ipynb`
- **EstatÃ­sticas descritivas**: MÃ©dias, medianas, desvios padrÃ£o
- **VisualizaÃ§Ãµes**: DistribuiÃ§Ãµes, correlaÃ§Ãµes, comparaÃ§Ãµes entre grupos
- **IdentificaÃ§Ã£o de padrÃµes**: RelaÃ§Ãµes entre features e evasÃ£o
- **Insights principais**:
  - Taxa de evasÃ£o geral do dataset
  - Features mais correlacionadas com evasÃ£o
  - DiferenÃ§as entre estudantes que evadiram e nÃ£o evadiram

#### **PreparaÃ§Ã£o para Modelagem**
- **SeleÃ§Ã£o de features**: Todas as features disponÃ­veis sÃ£o utilizadas (apÃ³s anÃ¡lise de correlaÃ§Ã£o)
- **TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas**: 
  - **One-Hot Encoding / Label Encoding**: VariÃ¡veis categÃ³ricas (ex: `gender`) sÃ£o codificadas numericamente
  - UtilizaÃ§Ã£o de `LabelEncoder` do scikit-learn
- **NormalizaÃ§Ã£o**: 
  - AplicaÃ§Ã£o de `StandardScaler` para modelos que requerem normalizaÃ§Ã£o (RegressÃ£o LogÃ­stica, KNN)
  - Random Forest nÃ£o requer normalizaÃ§Ã£o
- **DivisÃ£o Train/Test**:
  - **80% treino / 20% teste**
  - **Stratified Split**: MantÃ©m proporÃ§Ã£o de classes em ambos os conjuntos
  - **Random State**: 42 para reprodutibilidade

---

## ğŸ¤– Parte 3: O CoraÃ§Ã£o do Projeto - Modelagem e AvaliaÃ§Ã£o Comparativa (6,0 pontos)

### 3.1 Treinamento de TrÃªs Modelos

Foram treinados trÃªs algoritmos diferentes, apropriados para classificaÃ§Ã£o binÃ¡ria:

1. **RegressÃ£o LogÃ­stica**
   - **Tipo**: Modelo linear interpretÃ¡vel
   - **Vantagens**: Simples, rÃ¡pido, fornece probabilidades, interpretÃ¡vel
   - **Uso**: Baseline para comparaÃ§Ã£o

2. **Random Forest**
   - **Tipo**: Ensemble de Ã¡rvores de decisÃ£o
   - **Vantagens**: Robusto, lida bem com nÃ£o-linearidades, menos propenso a overfitting
   - **Uso**: Modelo mais complexo e poderoso

3. **KNN (K-Nearest Neighbors)**
   - **Tipo**: MÃ©todo nÃ£o-paramÃ©trico baseado em proximidade
   - **Vantagens**: Simples, nÃ£o assume distribuiÃ§Ã£o dos dados
   - **Uso**: ComparaÃ§Ã£o com mÃ©todos nÃ£o-paramÃ©tricos

### 3.2 AvaliaÃ§Ã£o com TrÃªs MÃ©tricas

Foram utilizadas **quatro mÃ©tricas** para avaliaÃ§Ã£o completa:

#### **3.2.1 AcurÃ¡cia (Accuracy)**
- **O que mede**: Taxa de acertos gerais do modelo
- **FÃ³rmula**: (VP + VN) / (VP + VN + FP + FN)
- **RelevÃ¢ncia**: DÃ¡ uma visÃ£o geral do desempenho, mas pode ser enganosa em datasets desbalanceados
- **InterpretaÃ§Ã£o**: Quanto maior, melhor (0 a 1)

#### **3.2.2 PrecisÃ£o (Precision)**
- **O que mede**: Entre os estudantes preditos como evasÃ£o, quantos realmente evadiram
- **FÃ³rmula**: VP / (VP + FP)
- **RelevÃ¢ncia**: **Importante para evitar alarmes falsos**. Queremos ter certeza quando identificamos um estudante em risco, para nÃ£o desperdiÃ§ar recursos com intervenÃ§Ãµes desnecessÃ¡rias.
- **InterpretaÃ§Ã£o**: Quanto maior, melhor (0 a 1)

#### **3.2.3 Recall (Sensibilidade)**
- **O que mede**: Entre os estudantes que realmente evadiram, quantos foram identificados pelo modelo
- **FÃ³rmula**: VP / (VP + FN)
- **RelevÃ¢ncia**: **CRUCIAL para nosso problema!** NÃ£o podemos deixar passar estudantes em risco de evasÃ£o. Um falso negativo (estudante em risco nÃ£o identificado) Ã© muito mais grave que um falso positivo.
- **InterpretaÃ§Ã£o**: Quanto maior, melhor (0 a 1)

#### **3.2.4 F1-Score**
- **O que mede**: MÃ©dia harmÃ´nica entre PrecisÃ£o e Recall
- **FÃ³rmula**: 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
- **RelevÃ¢ncia**: Balanceia PrecisÃ£o e Recall, Ãºtil quando precisamos de um equilÃ­brio entre ambos. Ã‰ especialmente Ãºtil quando temos classes desbalanceadas.
- **InterpretaÃ§Ã£o**: Quanto maior, melhor (0 a 1)

**MÃ©trica Adicional: ROC-AUC**
- TambÃ©m calculada para anÃ¡lise complementar
- Mede a capacidade do modelo de distinguir entre as classes

### 3.3 AnÃ¡lise Comparativa dos Resultados

Os resultados sÃ£o apresentados em uma **tabela comparativa** com todas as mÃ©tricas para cada modelo.

**CritÃ©rios de SeleÃ§Ã£o do Melhor Modelo:**
- **F1-Score** Ã© utilizado como mÃ©trica principal para seleÃ§Ã£o, pois balanceia PrecisÃ£o e Recall
- AnÃ¡lise de trade-offs entre mÃ©tricas
- ConsideraÃ§Ã£o do contexto de negÃ³cio (Recall Ã© prioritÃ¡rio)

**DiscussÃ£o Detalhada dos Resultados:**

**AnÃ¡lise por Modelo:**

1. **RegressÃ£o LogÃ­stica**:
   - Obteve a melhor acurÃ¡cia (0.8850) e precisÃ£o perfeita (1.0000)
   - No entanto, apresenta recall muito baixo (0.0800), o que Ã© problemÃ¡tico para nosso caso de uso
   - Isso indica que o modelo Ã© muito conservador, evitando falsos positivos mas perdendo muitos casos reais de evasÃ£o
   - Para um problema de evasÃ£o estudantil, onde nÃ£o podemos deixar passar estudantes em risco, o recall baixo Ã© uma limitaÃ§Ã£o crÃ­tica
   - O F1-Score de 0.1481, apesar de ser o melhor entre os trÃªs modelos, ainda Ã© muito baixo, refletindo o desequilÃ­brio entre precisÃ£o e recall

2. **Random Forest**:
   - AcurÃ¡cia competitiva (0.8750), prÃ³xima Ã  RegressÃ£o LogÃ­stica
   - Melhor ROC-AUC (0.5791), indicando melhor capacidade de discriminaÃ§Ã£o entre as classes
   - No entanto, nÃ£o conseguiu identificar nenhum caso de evasÃ£o (recall = 0, precisÃ£o = 0)
   - Isso sugere que o modelo pode estar sofrendo com o desbalanceamento de classes (apenas 12.7% de evasÃ£o)
   - O modelo estÃ¡ predizendo sempre a classe majoritÃ¡ria (nÃ£o evasÃ£o), o que explica a acurÃ¡cia alta mas mÃ©tricas zero para a classe positiva

3. **KNN (K-Nearest Neighbors)**:
   - AcurÃ¡cia mais baixa (0.8600) entre os trÃªs modelos
   - TambÃ©m nÃ£o identificou casos de evasÃ£o (recall = 0, precisÃ£o = 0)
   - Pode estar sendo afetado pela normalizaÃ§Ã£o ou pela escolha do parÃ¢metro k
   - Similar ao Random Forest, estÃ¡ predizendo sempre a classe majoritÃ¡ria

**Trade-offs e DecisÃ£o Final:**

Apesar do RegressÃ£o LogÃ­stica ter sido selecionado por ter o melhor F1-Score, Ã© importante notar que:
- O recall muito baixo (0.08) significa que estamos perdendo aproximadamente 92% dos casos reais de evasÃ£o
- Para o contexto de negÃ³cio, onde nÃ£o podemos deixar passar estudantes em risco, isso Ã© crÃ­tico
- A precisÃ£o perfeita (1.0) indica que quando o modelo prediz evasÃ£o, estÃ¡ sempre correto, mas isso acontece muito raramente

**LimitaÃ§Ãµes Identificadas:**
- **Desbalanceamento de Classes**: O dataset tem apenas 12.7% de casos de evasÃ£o, o que dificulta o aprendizado da classe minoritÃ¡ria
- **Threshold de DecisÃ£o**: O threshold padrÃ£o (0.5) pode nÃ£o ser ideal para este problema desbalanceado
- **Falta de Features**: Pode ser necessÃ¡rio incluir mais features relevantes ou criar features derivadas mais informativas

**RecomendaÃ§Ãµes para Melhoria:**
- **Balanceamento de Classes**: Implementar tÃ©cnicas como SMOTE (Synthetic Minority Oversampling Technique) ou undersampling da classe majoritÃ¡ria
- **Ajuste de Threshold**: Reduzir o threshold de decisÃ£o para aumentar o recall, mesmo que isso reduza a precisÃ£o
- **TÃ©cnicas de Ensemble**: Combinar mÃºltiplos modelos ou usar tÃ©cnicas como class weights para dar mais peso Ã  classe minoritÃ¡ria
- **Coleta de Mais Dados**: Especialmente de casos de evasÃ£o, para melhorar o aprendizado
- **Feature Engineering**: Criar features mais preditivas baseadas no conhecimento de domÃ­nio

**Justificativa da Escolha para o Problema de NegÃ³cio:**

Embora o RegressÃ£o LogÃ­stica tenha limitaÃ§Ãµes significativas, foi escolhido porque:
- Ã‰ o Ãºnico modelo que conseguiu identificar pelo menos alguns casos de evasÃ£o (recall > 0)
- Tem precisÃ£o perfeita, garantindo que quando identifica um estudante em risco, estÃ¡ correto
- Ã‰ interpretÃ¡vel, permitindo entender quais features sÃ£o mais importantes
- Pode ser melhorado com as tÃ©cnicas mencionadas acima

**Para ProduÃ§Ã£o:**
- Recomenda-se ajustar o threshold de probabilidade para aumentar o recall
- Implementar monitoramento contÃ­nuo das mÃ©tricas em produÃ§Ã£o
- Considerar um sistema de alertas em mÃºltiplos nÃ­veis de risco (baixo, mÃ©dio, alto)

**VisualizaÃ§Ãµes:**
- GrÃ¡ficos comparativos de mÃ©tricas
- Matrizes de confusÃ£o para cada modelo
- Curvas ROC para anÃ¡lise de discriminaÃ§Ã£o

---

## ğŸš¢ Parte 4: Tornando o Modelo Ãštil - Deploy (2,0 pontos)

### 4.1 Salvando o Modelo Treinado

ApÃ³s a seleÃ§Ã£o do melhor modelo na Parte 3, o modelo Ã© salvo usando `joblib`:

```python
import joblib

# Salvar modelo
joblib.dump(meu_melhor_modelo, 'modelo_final.pkl')

# Salvar prÃ©-processadores (se necessÃ¡rio)
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(label_encoders, 'label_encoders.pkl')
```

**Arquivos Salvos:**
- `modelo_final.pkl`: Modelo treinado
- `scaler.pkl`: Normalizador (se o modelo requer)
- `label_encoders.pkl`: Encoders para variÃ¡veis categÃ³ricas

### 4.2 Carregando e Utilizando o Modelo

O script `deploy_model.py` demonstra como:

1. **Carregar o modelo salvo**:
```python
model = joblib.load('modelo_final.pkl')
scaler = joblib.load('scaler.pkl')
label_encoders = joblib.load('label_encoders.pkl')
```

2. **Preparar dados de um novo estudante**:
```python
novo_estudante = {
    'age': 20,
    'gender': 'M',
    'avg_grade': 5.0,
    # ... outras features
}
```

3. **Fazer prediÃ§Ã£o**:
```python
prediction = model.predict(prepared_data)
probability = model.predict_proba(prepared_data)
```

4. **Interpretar o resultado**:
- **PrediÃ§Ã£o**: 0 (nÃ£o evadiu) ou 1 (evadiu)
- **Probabilidade**: Percentual de chance de evasÃ£o
- **AÃ§Ã£o**: RecomendaÃ§Ã£o baseada no risco

**Exemplo de Uso:**
O script `deploy_model.py` inclui dois exemplos:
- **Estudante com alto risco**: Demonstra como o modelo identifica estudantes em risco
- **Estudante com baixo risco**: Demonstra como o modelo identifica estudantes seguros

**InterpretaÃ§Ã£o do Resultado:**
- Se o modelo prediz **evasÃ£o (1)** com alta probabilidade (>70%), recomenda-se **intervenÃ§Ã£o imediata**
- Se prediz **nÃ£o evasÃ£o (0)** com alta probabilidade, o estudante estÃ¡ em **baixo risco**

---

## ğŸ“ˆ Resultados Esperados

ApÃ³s executar o projeto completo, vocÃª terÃ¡:

1. âœ… Dataset sintÃ©tico gerado (`data/student_dropout_dataset.csv`)
2. âœ… AnÃ¡lise exploratÃ³ria completa (notebook `01_eda_exploratoria.ipynb`)
3. âœ… TrÃªs modelos treinados e avaliados
4. âœ… ComparaÃ§Ã£o detalhada de desempenho
5. âœ… Modelo final salvo (`modelo_final.pkl`)
6. âœ… Script de deploy funcional demonstrando uso do modelo

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **pandas**: ManipulaÃ§Ã£o de dados
- **numpy**: OperaÃ§Ãµes numÃ©ricas
- **scikit-learn**: Machine Learning
- **matplotlib/seaborn**: VisualizaÃ§Ãµes
- **jupyter**: Notebooks interativos
- **joblib**: SerializaÃ§Ã£o de modelos

---

## ğŸ“ Notas Importantes

- O projeto suporta tanto datasets **reais** quanto **sintÃ©ticos**
- O dataset real Ã© preferencial e baseado em dados anonimizados de evasÃ£o estudantil
- O dataset sintÃ©tico Ã© uma alternativa Ãºtil para testes rÃ¡pidos ou quando nÃ£o hÃ¡ acesso Ã  internet
- Os resultados podem variar ligeiramente devido Ã  aleatoriedade, mas sÃ£o reproduzÃ­veis com `random_state=42`
- O modelo selecionado pode variar dependendo dos dados, mas o processo de seleÃ§Ã£o Ã© sempre baseado em F1-Score

---

## ğŸ‘¥ Autores

Trabalho desenvolvido para a avaliaÃ§Ã£o N3 - CiÃªncia de Dados

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais.

---

**Ãšltima atualizaÃ§Ã£o**: Dezembro 2025
